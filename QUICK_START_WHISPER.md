# ğŸš€ Quick Start: Whisper Local Transcription

Get Whisper transcription running in 5 minutes!

## âš¡ Quick Setup

### 1. Install Python Backend (5 minutes)

```bash
# Navigate to whisper-backend
cd whisper-backend

# Create virtual environment
python -m venv venv

# Activate it
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install PyTorch with AMD GPU support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7

# Install dependencies
pip install -r requirements.txt
```

### 2. Start Both Servers

**Terminal 1 - Whisper Backend:**
```bash
cd whisper-backend
# Windows:
start.bat
# Linux/Mac:
chmod +x start.sh
./start.sh
```

**Terminal 2 - Next.js Frontend:**
```bash
npm run dev
```

### 3. Use It!

1. Go to `http://localhost:3000`
2. Start an interview session
3. In the transcript panel, toggle the switch from `â˜ï¸ Cloud` to `ğŸ™ï¸ Local`
4. Click "Connect"
5. You should see "ğŸ™ï¸ Whisper (Local GPU) â€¢ Connected"

## âœ… Verify It's Working

You should see in the Python terminal:
```
ğŸš€ Initializing Whisper model...
ğŸ® AMD GPU Available: True
ğŸ”§ Using device: cuda
âœ… Whisper model loaded successfully!
ğŸŒ Running on http://localhost:5000
```

## ğŸ†˜ Quick Troubleshooting

**Python server won't start?**
```bash
pip install flask flask-cors flask-socketio faster-whisper numpy
```

**No GPU detected?**
- Server will automatically use CPU (slower but works!)
- Install AMD ROCm drivers for GPU support

**Connection errors?**
- Make sure both servers are running
- Check if port 5000 is available
- Refresh the browser page

## ğŸ“š Full Documentation

For detailed setup, troubleshooting, and configuration:
- See `WHISPER_SETUP_GUIDE.md`
- See `whisper-backend/README.md`

## ğŸ¯ Features

- âœ… Free (no API costs!)
- âœ… Fast with AMD GPU
- âœ… Works offline
- âœ… 90+ languages supported
- âœ… Easy toggle between cloud and local

Enjoy your local transcription! ğŸ™ï¸

